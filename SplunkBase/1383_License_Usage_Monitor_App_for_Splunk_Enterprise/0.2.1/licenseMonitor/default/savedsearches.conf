# Summarize Index Volume by Host
[dailyIndexGBByHost_7d]
action.email.reportServerEnabled = 0
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1mon@d
auto_summarize.timespan = 1m
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
search = index=_internal per_host_thruput | eval gb=kb/1024/1024 | timechart limit=50 minspan=1d sum(gb) by series | addcoltotals

# Summarize Index Volume by Index
[dailyIndexGbByIndex_7d]
action.email.reportServerEnabled = 0
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1mon@d
auto_summarize.timespan = 1m
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
search = index=_internal  group="per_index_thruput" | eval gb=kb/1024/1024 | timechart limit=50 minspan=1d sum(gb) by series | addcoltotals

# Summarize Index Volume by Sourcetype
[dailyIndexGbBySourcetype_7d]
action.email.reportServerEnabled = 0
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1mon@d
auto_summarize.timespan = 1m
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
search = index=_internal  group="per_sourcetype_thruput" | eval gb=kb/1024/1024 | timechart limit=50 minspan=1d sum(gb) by series | addcoltotals

# Summarize Index Volume by Index...made for pumping into a graph
[dailyIndexGBTotal]
action.email.reportServerEnabled = 0
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1mon@d
auto_summarize.timespan = 1m
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
display.general.type = visualizations
display.page.search.mode = fast
display.visualizations.charting.chart = area
display.visualizations.charting.chart.stackMode = stacked
request.ui_dispatch_view = search
search = index=_internal source=*license_usage.log type=Usage |  eval totalMB = b/1024/1024  | eval totalGB = totalMB /1024 | rename idx as index | timechart span=1d sum(totalGB) by index


# Summarize Index Volume by Index by hour...made for pumping into a graph
[hourlyIndexGBTotal]
action.email.reportServerEnabled = 0
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1w@d
auto_summarize.timespan = 1m
dispatch.earliest_time = @d
dispatch.latest_time = now
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
search = index=_internal metrics kb group="per_index_thruput" NOT series=_* NOT series="*summary*" | eval totalMB = kb /1024  | eval totalGB = totalMB /1024 | timechart span=1h sum(totalGB) by series

# Missing forwarder search
[MissingForwarder_30day]
action.email.reportServerEnabled = 0
alert.suppress = 0
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1mon@d
auto_summarize.timespan = 1m
dispatch.earliest_time = -30d@d
dispatch.latest_time = now
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
search = `all_forwarders` | search status=missing | fields sourceHost,lastConnected | sort -lastConnected

# Better 7-day analysis saved search
[ForwarderAnalysis_7day]
action.email.reportServerEnabled = 0
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -1mon@d
auto_summarize.timespan = 1m
dispatch.earliest_time = -7d@h
dispatch.latest_time = now
displayview = flashtimeline
request.ui_dispatch_view = flashtimeline
search = index="_internal" source="*metrics.log" group=tcpin_connections |\
eval sourceHost=if(isnull(hostname), sourceHost,hostname) |\
eval connectionType=case(fwdType=="uf","Universal Forwarder",\
fwdType=="lwf", "Light Weight Forwarder",fwdType=="full", "Splunk\
Indexer", connectionType=="cooked" or connectionType=="cookedSSL","Splunk\
Forwarder", connectionType=="raw" or connectionType=="rawSSL","Legacy\
Forwarder") |\
eval build=if(isnull(build),"n/a",build) |\
eval version=if(isnull(version),"pre 4.2",version) |\
eval guid=if(isnull(guid),sourceHost,guid) |\
eval os=if(isnull(os),"n/a",os)|\
eval arch=if(isnull(arch),"n/a",arch) |\
eval my_splunk_server = splunk_server |\
fields connectionType sourceIp sourceHost sourcePort destPort kb tcp_eps\
tcp_Kprocessed tcp_KBps my_splunk_server build version os arch |\
eval lastReceived = if(kb>0, _time, null) |\
stats first(sourceIp) as sourceIp first(connectionType) as connectionType\
first(sourcePort) as sourcePort first(build) as build first(version) as\
version first(os) as os first(arch) as arch max(_time) as lastConnected\
max(lastReceived) as lastReceived sum(kb) as kb avg(tcp_eps) as avg_eps by\
sourceHost |\
stats first(sourceIp) as sourceIp first(connectionType) as connectionType\
first(sourcePort) as sourcePort first(build) as build first(version) as\
version first(os) as os first(arch) as arch max(lastConnected) as\
lastConnected max(lastReceived) as lastReceived first(kb) as KB\
first(avg_eps) as eps by sourceHost |\
eval status = if(isnull(KB) or\
lastConnected<(info_max_time-900),"missing",if(lastConnected>(lastReceived+\
300) or KB==0,"quiet","active")) |\
convert ctime(lastConnected) as lastConnected |\
convert ctime(lastReceived) as lastReceived |\
sort lastConnected

[Yesterday's Volume]
action.email.inline = 1
action.email.reportServerEnabled = 0
alert.suppress = 0
alert.track = 0
auto_summarize = 1
auto_summarize.dispatch.earliest_time = -7d@d
cron_schedule = 5 0 * * *
dispatch.earliest_time = -d@d
dispatch.latest_time = @d
display.general.type = visualizations
display.page.search.mode = fast
display.visualizations.charting.chart = markerGauge
display.visualizations.charting.chart.rangeValues = [0,"600","700","1000"]
display.visualizations.charting.gaugeColors = [0x84e900,0xffe800,0xbf3030]
enableSched = 1
request.ui_dispatch_view = search
search = index=_internal source=*license_usage.log type=Usage \
| eval usedMB = b/1024/1024  | eval usedGB = usedMB /1024 | eval totalGB = poolsz/1024/1024/1024 \
| eval gauge_base=0\
| eval gauge_danger=totalGB*0.8\
| eval gauge_top=totalGB+0.001\
| stats sum(usedGB) as usedGB max(totalGB) as totalGB\
| gauge usedGB gauge_base gauge_danger totalGB gauge_top

[hourlyIndexGBTotal]
dispatch.earliest_time = -1d
display.general.type = visualizations
display.page.search.mode = fast
display.visualizations.charting.chart = area
display.visualizations.charting.chart.stackMode = stacked
request.ui_dispatch_view = search
search = index=_internal source=*license_usage.log type=Usage |  eval totalMB = b/1024/1024  | eval totalGB = totalMB /1024 | rename idx as index | timechart span=1h limit=20 sum(totalGB) by index
